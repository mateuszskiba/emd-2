{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EMD-2-ver2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7c72-N0RGo1z","colab_type":"code","outputId":"c520c9cf-2151-478a-c848-aa18767f9842","executionInfo":{"status":"ok","timestamp":1579986759996,"user_tz":-60,"elapsed":19749,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ds8aZ8OFzw8","colab_type":"code","outputId":"c8bfe163-1b0d-433c-b7ed-6389c8eb7d64","executionInfo":{"status":"ok","timestamp":1579986802500,"user_tz":-60,"elapsed":62232,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Install necessary packages -> uncomment what is currently needed\n","\n","!pip install unidecode\n","!pip install contractions\n","!pip install wordsegment\n","!pip install -U symspellpy\n","!pip install emoji --upgrade\n","!pip install -U imbalanced-learn\n","!pip install bert-for-tf2\n","!pip install transformers\n","# !pip install nltk"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\r\u001b[K     |█▍                              | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 5.1MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.1.1\n","Collecting contractions\n","  Downloading https://files.pythonhosted.org/packages/85/41/c3dfd5feb91a8d587ed1a59f553f07c05f95ad4e5d00ab78702fbf8fe48a/contractions-0.0.24-py2.py3-none-any.whl\n","Collecting textsearch\n","  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n","Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n","Collecting pyahocorasick\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n","\u001b[K     |████████████████████████████████| 317kB 6.4MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81706 sha256=20b54ec9a07da9d176f3aeb883b7569fa5fc19bb9f27f088af7d2c27da76449e\n","  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n","Successfully built pyahocorasick\n","Installing collected packages: pyahocorasick, textsearch, contractions\n","Successfully installed contractions-0.0.24 pyahocorasick-1.4.0 textsearch-0.0.17\n","Collecting wordsegment\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/6c/e6f4734d6f7d28305f52ec81377d7ce7d1856b97b814278e9960183235ad/wordsegment-1.3.1-py2.py3-none-any.whl (4.8MB)\n","\u001b[K     |████████████████████████████████| 4.8MB 4.9MB/s \n","\u001b[?25hInstalling collected packages: wordsegment\n","Successfully installed wordsegment-1.3.1\n","Collecting symspellpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/0b/2daa14bf1ed649fff0d072b2e51ae98d8b45cae6cf8fdda41be01ce6c289/symspellpy-6.5.2-py3-none-any.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 4.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.17.5)\n","Installing collected packages: symspellpy\n","Successfully installed symspellpy-6.5.2\n","Collecting emoji\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42175 sha256=262a142e7356463f985f8bc92b817d14eb8d9b03ecd34357704e7d5c0a997a3c\n","  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-0.5.4\n","Collecting imbalanced-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/aa/eba717a14df36f0b6f000ebfaf24c3189cd7987130f66cc3513efead8c2a/imbalanced_learn-0.6.1-py3-none-any.whl (162kB)\n","\u001b[K     |████████████████████████████████| 163kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n","Installing collected packages: imbalanced-learn\n","  Found existing installation: imbalanced-learn 0.4.3\n","    Uninstalling imbalanced-learn-0.4.3:\n","      Successfully uninstalled imbalanced-learn-0.4.3\n","Successfully installed imbalanced-learn-0.6.1\n","Collecting bert-for-tf2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/15/03314e558f4c34642a90144fc8ec8bdbb0ef3c2ca80345007f9c7b007a07/bert-for-tf2-0.13.4.tar.gz (40kB)\n","\u001b[K     |████████████████████████████████| 40kB 2.8MB/s \n","\u001b[?25hCollecting py-params>=0.7.3\n","  Downloading https://files.pythonhosted.org/packages/ec/17/71c5f3c0ab511de96059358bcc5e00891a804cd4049021e5fa80540f201a/py-params-0.8.2.tar.gz\n","Collecting params-flow>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/0d/12/2604f88932f285a473015a5adabf08496d88dad0f9c1228fab1547ccc9b5/params-flow-0.7.4.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.7.1->bert-for-tf2) (1.17.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.7.1->bert-for-tf2) (4.28.1)\n","Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.13.4-cp36-none-any.whl size=29942 sha256=887654e9e7f8bba6bb263831057dd7b594e925a4c82372282401fa402ecb2bb0\n","  Stored in directory: /root/.cache/pip/wheels/d1/14/6d/b36f1618f939480ce5baa48e4d918ea00669f1cbbec4419514\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.8.2-cp36-none-any.whl size=4633 sha256=460f45ad44b57b5629d30bb2c7a25723addd7f63c207fd9fa3126aca24653e16\n","  Stored in directory: /root/.cache/pip/wheels/83/3a/9c/baf35d6f17f0c2c6b61bf8ac3ab9fc12df0e41432ccaeecacb\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.7.4-cp36-none-any.whl size=16196 sha256=9f471d3551de80dca694d8c319d374678777511218e566323b442ecda4793e19\n","  Stored in directory: /root/.cache/pip/wheels/86/30/40/507b60d68b67ac87f35e95c98f5b296a32f146d5ae1d1d5aa7\n","Successfully built bert-for-tf2 py-params params-flow\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.13.4 params-flow-0.7.4 py-params-0.8.2\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n","\u001b[K     |████████████████████████████████| 450kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 48.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 42.2MB/s \n","\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=168151e2393148db4ff4010d2f766247a330f6bcf46b7acd90712dea3d9bf13a\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7864AKjDrMsa","colab_type":"code","outputId":"f13c278c-f0bf-459e-e008-c70c8e1bb3a2","executionInfo":{"status":"ok","timestamp":1579986818159,"user_tz":-60,"elapsed":77875,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":165}},"source":["# All imports - DO NOT CHANGE THE ORDER OF INSTRUCTIONS\n","!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n","\n","import re\n","import os\n","import sys\n","import json\n","\n","if not 'bert_repo' in sys.path:\n","    sys.path.insert(0, 'bert_repo')\n","\n","import logging\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import string\n","from sklearn.model_selection import train_test_split\n","import spacy\n","from bs4 import BeautifulSoup\n","import unidecode\n","import contractions\n","import gensim.downloader as api\n","import re\n","import wordsegment\n","import pkg_resources\n","from symspellpy.symspellpy import SymSpell, Verbosity\n","import emoji\n","from imblearn.over_sampling import SMOTE\n","import tensorflow.compat.v1 as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.models import Model\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n","from modeling import BertModel, BertConfig\n","from tokenization import FullTokenizer, convert_to_unicode\n","from extract_features import InputExample, convert_examples_to_features\n","from tqdm import tqdm\n","#import tensorflow_addons as tfa\n","# import nltk\n","from google.colab import auth, drive\n","# nltk.download('punkt')\n","\n","wordsegment.load()\n","\n","# Load SymSpell -> package for correcting misspellings\n","sym_spell = SymSpell(2, 7)\n","\n","dictionary_path = pkg_resources.resource_filename(\n","    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n","bigram_path = pkg_resources.resource_filename(\n","    \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n","\n","sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n","sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n","\n","# get TF logger \n","log = logging.getLogger('tensorflow')\n","log.handlers = []"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'bert_repo'...\n","remote: Enumerating objects: 336, done.\u001b[K\n","remote: Total 336 (delta 0), reused 0 (delta 0), pack-reused 336\n","Receiving objects: 100% (336/336), 290.24 KiB | 1.64 MiB/s, done.\n","Resolving deltas: 100% (184/184), done.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"QTH_igc87s5u","colab_type":"code","outputId":"f03efb49-0103-4102-bf08-358bcac53dc4","executionInfo":{"status":"ok","timestamp":1579986818798,"user_tz":-60,"elapsed":78499,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["#Import data\n","training_dataset = pd.read_csv('gdrive/My Drive/ITI/EMD/train.csv', dtype={'Id': object})\n","training_dataset = training_dataset.replace({ 'Category': { 'positive': 0, 'neutral': 1, 'negative': 2 } })\n","print(training_dataset.shape)\n","training_dataset.head()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(4000, 3)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Category</th>\n","      <th>Tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>628949369883000832</td>\n","      <td>2</td>\n","      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>628976607420645377</td>\n","      <td>2</td>\n","      <td>@Microsoft how about you make a system that do...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>629023169169518592</td>\n","      <td>2</td>\n","      <td>I may be ignorant on this issue but... should ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>629179223232479232</td>\n","      <td>2</td>\n","      <td>Thanks to @microsoft, I just may be switching ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>629186282179153920</td>\n","      <td>1</td>\n","      <td>If I make a game as a #windows10 Universal App...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   Id  ...                                              Tweet\n","0  628949369883000832  ...  dear @Microsoft the newOoffice for Mac is grea...\n","1  628976607420645377  ...  @Microsoft how about you make a system that do...\n","2  629023169169518592  ...  I may be ignorant on this issue but... should ...\n","3  629179223232479232  ...  Thanks to @microsoft, I just may be switching ...\n","4  629186282179153920  ...  If I make a game as a #windows10 Universal App...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"rDEgNCTGWsT6","colab_type":"code","outputId":"67c3e831-de95-47d8-8b36-426d65ed7fc1","executionInfo":{"status":"ok","timestamp":1579986818802,"user_tz":-60,"elapsed":78489,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Remove invalid row\n","training_dataset = training_dataset[training_dataset['Category'] != 'Tweet']"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  result = method(y)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WsX3C0SY9816","colab_type":"code","outputId":"b9976c74-e8e1-46ab-8dea-a7cfbaf84d1b","executionInfo":{"status":"ok","timestamp":1579986818804,"user_tz":-60,"elapsed":78477,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# Concatenate\n","training_dataset = training_dataset.reset_index(drop=True)\n","print(training_dataset.shape)\n","training_dataset.head()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(4000, 3)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Category</th>\n","      <th>Tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>628949369883000832</td>\n","      <td>2</td>\n","      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>628976607420645377</td>\n","      <td>2</td>\n","      <td>@Microsoft how about you make a system that do...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>629023169169518592</td>\n","      <td>2</td>\n","      <td>I may be ignorant on this issue but... should ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>629179223232479232</td>\n","      <td>2</td>\n","      <td>Thanks to @microsoft, I just may be switching ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>629186282179153920</td>\n","      <td>1</td>\n","      <td>If I make a game as a #windows10 Universal App...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   Id  ...                                              Tweet\n","0  628949369883000832  ...  dear @Microsoft the newOoffice for Mac is grea...\n","1  628976607420645377  ...  @Microsoft how about you make a system that do...\n","2  629023169169518592  ...  I may be ignorant on this issue but... should ...\n","3  629179223232479232  ...  Thanks to @microsoft, I just may be switching ...\n","4  629186282179153920  ...  If I make a game as a #windows10 Universal App...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"7SCUV0cc9ZIR","colab_type":"code","outputId":"09d16c70-e31e-4760-aaa5-82db54cab752","executionInfo":{"status":"ok","timestamp":1579986819041,"user_tz":-60,"elapsed":78700,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["#Import data\n","test_dataset = pd.read_csv('gdrive/My Drive/ITI/EMD/test.csv', dtype={'Id': object}).dropna()\n","print(test_dataset.shape)\n","test_dataset.head()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(4000, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>628949369883000832</td>\n","      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>628976607420645377</td>\n","      <td>@Microsoft how about you make a system that do...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>629023169169518592</td>\n","      <td>Not Available</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>629179223232479232</td>\n","      <td>Not Available</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>629186282179153920</td>\n","      <td>If I make a game as a #windows10 Universal App...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   Id                                              Tweet\n","0  628949369883000832  dear @Microsoft the newOoffice for Mac is grea...\n","1  628976607420645377  @Microsoft how about you make a system that do...\n","2  629023169169518592                                      Not Available\n","3  629179223232479232                                      Not Available\n","4  629186282179153920  If I make a game as a #windows10 Universal App..."]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"73i5BO8TqoTE","colab_type":"text"},"source":["# **Training and validation sets**"]},{"cell_type":"code","metadata":{"id":"-xHoiMYYlJQk","colab_type":"code","colab":{}},"source":["training_examples, validation_examples = train_test_split(training_dataset, test_size=0.1)\n","\n","training_x = np.array(training_examples['Tweet'])\n","validation_x = np.array(validation_examples['Tweet'])\n","training_y = np.array(training_examples['Category'])\n","validation_y = np.array(validation_examples['Category'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o2bNpHc9qMpw","colab_type":"text"},"source":["# **Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"fao-Vte1gtJ2","colab_type":"text"},"source":["### Common preprocessing functions"]},{"cell_type":"code","metadata":{"id":"Re0mCq1ogs6a","colab_type":"code","colab":{}},"source":["# remove html tags if exist\n","def strip_html_tags(text):\n","    soup = BeautifulSoup(text, 'html.parser')\n","    stripped_text = soup.get_text(separator=' ')\n","    return stripped_text\n","\n","\n","# remove unnecessary whitespaces\n","def remove_whitespace(text):\n","    text = text.strip()\n","    return ' '.join(text.split())\n","\n","\n","# remove accented chars (e.g. caffè -> caffe)\n","def remove_accented_chars(text):\n","    text = unidecode.unidecode(text)\n","    return text\n","\n","\n","# remove hashes and split words (e.g. '#fortTrump' -> 'fort trump')\n","def split_hashtags(text):\n","    splitted = text.split()\n","    new_word_sequence = []\n","\n","    for chunk in splitted:\n","        if chunk[0] == '#':\n","            chunk = chunk[1:]\n","            new_word_sequence.extend(wordsegment.segment(chunk))\n","        else:\n","            new_word_sequence.append(chunk)\n","        \n","    return ' '.join(tuple(new_word_sequence))\n","\n","\n","def substitute_emojis(text):\n","    demojized_text = emoji.demojize(text)\n","    return re.compile('[_:]+').sub(' ', demojized_text)\n","\n","\n","def preprocess_common(text):\n","    text = strip_html_tags(text)\n","    text = contractions.fix(text)\n","    text = split_hashtags(text)\n","    text = substitute_emojis(text)\n","    text = remove_whitespace(text)\n","    text = remove_accented_chars(text)\n","    return text.lower()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kW6rr02WIpar","colab_type":"code","colab":{}},"source":["pattern = re.compile('^\\@\\w+')\n","# Replace user mentions with @user token\n","def replace_user_mentions(example):\n","  new_example = example[:]\n","  for i, e in enumerate(example):\n","    if pattern.match(e):\n","      new_example[i] = '@user'\n","  return new_example"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4Gjm9OhOzug","colab_type":"code","colab":{}},"source":["# Remove redundant @user tokens\n","def remove_redundant_users(example):\n","    user_count = 0\n","    new_example = example[:]\n","    for i, token in reversed(list(enumerate(example))):\n","        if token == '@user':\n","            user_count += 1\n","        if user_count > 3:\n","            new_example.pop(i)\n","    else:\n","        user_count = 0\n","\n","    return new_example"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1pJMq-8ygixr","colab_type":"text"},"source":["### Spacy preprocessing"]},{"cell_type":"code","metadata":{"id":"KPYd37I_giKk","colab_type":"code","colab":{}},"source":["# Try leaving '?' and '!' as far as punctuation is concerned\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","# exclude negation words from spacy stopwords list\n","deselect_stop_words = ['no', 'not', 'noone', 'none', 'lacks', 'lack', 'nor', 'never', 'neighter', 'hardly', 'nobody', 'nothing', 'lacking', 'nowhere']\n","for w in deselect_stop_words:\n","    nlp.vocab[w].is_stop = False\n","\n","def preprocess_spacy(text):\n","    doc = nlp(text)\n","\n","    clean_text = []\n","    \n","    for token in doc:\n","        flag = True\n","        edit = token.text\n","\n","        # remove punctuations\n","        if token.pos_ == 'PUNCT' and flag == True and token.text != '@user': \n","            flag = False\n","       \n","        # remove special characters\n","        if token.pos_ == 'SYM' and flag == True: \n","            flag = False\n","        \n","        # remove numbers\n","        if (token.pos_ == 'NUM' or token.text.isnumeric()) and flag == True:\n","            flag = False\n","\n","        # correct misspelings\n","        # if flag == True:\n","            # suggestions = sym_spell.lookup(edit, Verbosity.TOP, 2)\n","            # if len(suggestions) > 0:\n","                # edit = suggestions[0].term\n","\n","        # remove stop words\n","        if token.is_stop and token.pos_ != 'NUM': \n","            flag = False\n","\n","        # convert tokens to base form\n","        elif token.lemma_ != '-PRON-' and flag == True:\n","            edit = token.lemma_\n","\n","        # append tokens edited and not removed to list \n","        if edit != '' and flag == True:\n","            clean_text.append(edit)        \n","    \n","    return clean_text"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UlyyCkwWhFw1","colab_type":"text"},"source":["### Preprocessing execution"]},{"cell_type":"code","metadata":{"id":"MAHp6jlH12sD","colab_type":"code","outputId":"3eaeaffb-c3e2-49f8-882c-23a6ef035bb5","executionInfo":{"status":"ok","timestamp":1579986820023,"user_tz":-60,"elapsed":79644,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["cleaned_x = [preprocess_spacy(example) for example in training_x[0:30]]\n","users_x = [replace_user_mentions(example) for example in cleaned_x]\n","reduced_users_x = [remove_redundant_users(example) for example in users_x]\n","print(reduced_users_x[0:30])\n","print(training_x[0:30])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[['test', 'easy', 'insert', 'Galaxy', 'Note', 'S', 'Pen', 'backwards', 'damage', 'device', 'stylus', 'detection', 'mec', 'http://t.co/h0wrnmdksg'], ['tom', 'brady', 'support', 'Donald', 'trump', 'go', 'to', 'throw', 'pic', 'pull', 'hamstring', 'Thursday', 'night'], ['Angela', 'Merkel', 'say', 'border', 'control', 'restore', 'pity', ' ', 'listen', 'late'], ['Worlds', 'big', 'icon', 'David', 'Beckham', 'dine', '@user', '@user', 'Wednesday', 'Manchester', '#', 'Beckham', 'http://t.co/qznrpd4wzt'], ['frequent', 'flier', 'want', 'finally', 'Amazon', 'Prime', 'membership', 'http://t.co/eHXGq4I85B', '@user', '#', 'fly', 'Amazon'], ['tomorrow', 'morning', 'advanced', 'core', 'sculpt', 'Hillary', ' ', 'say', 'advanced', 'level', 'welcome'], ['Romeo', 'Beckham', 'lead', 'England', 'Wayne', 'Rooney', '13th', 'birthday', 'David', 'Beckham', 'clout', 'http://t.co/MQYMuYlMav'], ['fancy', 'join', 'Arsenal', 'v', 'Stoke', 'Sat', ' ', 'spare', 'ticket', 'sit', 'p.m.', 'kick'], ['cynical', 'electoral', 'board', 'preparation', 'snap', 'poll', 'November', 'Pres', 'Erdogan', 'refuse', 'gov', 'form', 'mandate', 'CHP'], ['@user', '@user', 'hey', 'idiot', 'bad', 'lose', 'read', 'SCOTUS', 'decision', 'Obergefell', 'google'], ['http://t.co/xdiii1c0MQ', 'british', 'council', 'chief', 'want', 'public', 'srvcs', 'resource', 'David', 'Cameron', 'refugee', 'cdnpoli', '#', 'refugeecrisis'], ['tomorrow', 'want', 'movie', 'day', 'think', 'go', 'Disneyland'], ['register', 'Exertis', '&', 'amp', 'IBM', 'Storage', 'Systems', 'Group', 'Know', 'Product', 'event', 'Thursday', 'Sept', 'Exertis', 'Ireland', 'http://t.co/qqz1ansbjp'], ['@user', '@user', '11:35pm', 'Emily', 'Blunt', 'U.S.', 'Air', 'Force', 'Airman', '1st', 'Class', 'Spencer', 'Stone', 'Rita', 'Ora', 'Chris', 'Brown', 'perform', 'Kimmel'], ['Bernie', 'Sanders', 'King', 'Reddit', 'not', 'lead', 'poll', 'Bernie', 'Sanders', 'win', 've', 'http://t.co/7zv1CJwsMg'], ['nice', 'evening', 'little', 'walk', 'Apple', 'Watch', 'tell', 'stand', 'well', 'listen', 'gettingfat', '#', 'sunday'], ['Amazon', 'Prime', 'deliver', 'Sunday', 'say'], ['@user', '@user', 'ik', \":'(\", 'nvm', 'tomorrow', 'Chris', 'Brown', 'like', 'rihanna'], ['tidal', 'Beyonce', 'performance', 'sure', 'somebody', 'upload', 'tomorrow'], ['Murray', 'give', 'expect', 'day', 'Federer', 'unbreakable', 'tb', '2nd', 'set', '#', 'CincyTennis'], ['go', 'Chris', 'brown', 'tour', 'Thursday', '#', 'chrisbrown#onehellofanighttour'], ['Amazon', '#', 'PreOrder', 'live', 'Vivid', 'Pre', 'order', 'copy', 'kindle', 'October', '11th', ' ', 'Amazon', 'http://t.co/ThdThD507V'], ['interesting', 'Sunday', 'read', 'rise', 'fall', 'rebirth', 'Google+', 'http://t.co/87csxrl8cv'], ['IBM', 'Spectrum', 'Protect', 'name', 'Gartner', 'leader', 'Quadrant', 'Enterprise', 'Backup', 'software', 'leader', '10th', 'time', 'http://t.co/Pbxo95Gup6'], ['ugh', 'forget', 'hannibal', 'end', 'never', 'keep', 'feel', 'pretty', 'sad', 'damn', 'good', '1st', 'season'], ['Apple', 'Watch', 'remind', 'hope', 'come', 'sooner', 'March', 'look', 'Valentine', 'Day'], ['travel', 'get', 'bit', 'pleasant', 'Amazon', 'Prime', 'subscriber', 'Tuesday', 'online', 'retail', 'giant', 'announced&amp;nbsp;that'], ['deep', 'Season', 'HANNIBAL', 'Graham', 'meet', 'match', 'Tooth', 'Fairy', 'http://t.co/aHbA8EnCJG', 'http://t.co/fJP8d00hgs'], ['Bentley', 'right', 'idea', '90', 'day', 'nice', 'cool', 'stone', 'basement', 'http://t.co/asrqtxhhdb'], ['love', ' ', 'bring', 'Chris', 'Brown', 'album', '-thursday', 'go', 'metal', '-saturday', 'see', 'Direction', '  ', 'music']]\n","[\"Tests show it is easy to insert Galaxy Note 5's S Pen backwards; doing so may damage device's stylus detection mec... http://t.co/H0wrNMDKSg\"\n"," \"tom brady supports Donald trump. Therefore he's gonna throw 4 pics and pull his hamstring on Thursday night.\"\n"," \"Angela Merkel says border controls may have to be restored It's a pity she didn't  listen before it was too late.\"\n"," 'One of the Worlds biggest icons David Beckham dined @TattuMCR in @Spinningfields this Wednesday #Manchester #Beckham http://t.co/QZNRpD4WZt'\n"," 'If you are a frequent flier, you may want to finally get that Amazon Prime membership... http://t.co/eHXGq4I85B via @UPROXX #Flying #Amazon'\n"," 'tomorrow morning 9:30am Advanced core and sculpt with Hillary!  Although it says advanced, all levels are welcome!'\n"," 'Romeo Beckham leads out England with Wayne Rooney for his 13th birthday: David Beckham used his clout with the... http://t.co/MQYMuYlMav'\n"," 'Anyone of you fancy joining me at Arsenal v Stoke on Sat?  I have 1 spare ticket (sat next to me) - 3pm kick off'\n"," 'So cynical of the electoral board to make preparations for snap polls on Nov. 1 as Pres. Erdogan refuses to give gov-forming mandate to CHP.'\n"," '@Augustine25 @Loincloth71 Hey, idiot. Too bad. You have lost. You may have read about the SCOTUS decision? Obergefell? Google that . . .'\n"," 'http://t.co/xdiii1c0MQ British council chiefs want more public srvcs resources from David Cameron for more refugees #cdnpoli #refugeecrisis'\n"," \"And tomorrow she wants to go to the movies. And the day after I think we're going to Disneyland.\"\n"," 'Register now for the Exertis &amp; IBM Storage Systems Group Know Your Product Event, Thursday 10 Sept @ Exertis Ireland. http://t.co/QqZ1ANsBJP'\n"," 'On @JimmyKimmelLive @WCVB at 11:35pm, Emily Blunt, U.S. Air Force Airman 1st Class Spencer Stone, Rita Ora with Chris Brown perform #Kimmel'\n"," 'Bernie Sanders: King of Reddit: Though he may not be leading in the polls, Bernie Sanders is winning in one ve... http://t.co/7zv1CJwsMg'\n"," 'Nice evening for a little walk. Apple Watch is telling me to stand up so better listen to it. #gettingfat #sunday'\n"," 'Amazon Prime deliver on a Sunday...just saying...'\n"," \"@aziq_adam @IzzyJizzy99 ik :'( nvm tomorrow I Chris Brown her like she's rihanna\"\n"," \"so you have to have tidal to see Beyonce performance? I'm sure somebody will upload it but tomorrow.\"\n"," \"Murray has given it his all, which wasn't expected after the last few days he has had but Federer just unbreakable. TB 2nd set. #CincyTennis\"\n"," 'Who else is going to the Chris brown tour this Thursday #ChrisBrown#onehellofanighttour'\n"," 'Amazon #PreOrder is #Live for Vivid!! Go Pre-Order your copy and have it on your kindle October 11th!  Amazon US:... http://t.co/ThdThD507V'\n"," 'Interesting Sunday read on the rise, fall and rebirth of Google+. http://t.co/87Csxrl8cV'\n"," 'IBM\\'s Spectrum Protect named Gartner\\'s \"Leaders\" Quadrant for Enterprise Backup Software: A Leader for the 10th time http://t.co/Pbxo95Gup6'\n"," 'ugh also i forgot hannibal is ending...i never kept up with it but i still feel pretty sad it was a damn good show, 1st season'\n"," \"What Apple Watch has reminded me hope it's coming sooner than March (looking at you Valentine's Day).\"\n"," \"Traveling just got a bit more pleasant for Amazon Prime subscribers. On Tuesday, the online retail giant announced&amp;nbsp;that it's now\"\n"," \"We're deep in Season 3 of HANNIBAL and Will Graham may have met his match with The Tooth Fairy http://t.co/aHbA8EnCJG http://t.co/fJP8d00hgs\"\n"," 'Bentley has the right idea! It may have been in the 90s all day, but nice and cool down in a stone basement after... http://t.co/ASRQtxhHdb'\n"," 'I love that:  -today, I brought a Chris Brown album. -Thursday, I am going to a metal show. -Saturday, I am seeing One Direction.   #music']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"btAs2RDT9uoS","colab_type":"text"},"source":["# **BERT**"]},{"cell_type":"markdown","metadata":{"id":"Yp5AzW_zilHm","colab_type":"text"},"source":["### BERT Preprocessing - single example\n"]},{"cell_type":"code","metadata":{"id":"J3woANjZiltJ","colab_type":"code","colab":{}},"source":["def remove_punctation(tokens):\n","    punctuation = [char for char in string.punctuation]\n","    return list(filter(lambda token: token not in punctuation, tokens))\n","\n","\n","def preprocess_bert_before_tokenization(text):\n","    preprocessed_text = preprocess_common(text)\n","    spacy_x = preprocess_spacy(preprocessed_text)\n","    users_x = replace_user_mentions(spacy_x)\n","    cleaned_x = remove_redundant_users(users_x)\n","    return ' '.join(cleaned_x)\n","\n","\n","def preprocess_bert_after_tokenization(tokenized_x):\n","    # update input_ids, input_mask, input_type_ids\n","    return remove_punctation(cleaned_x) # remove i.a. hyphens remainings from words like 'de-platforming'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dkqKH8ssRuFI","colab_type":"text"},"source":["### Getting the pre-trained model"]},{"cell_type":"code","metadata":{"id":"9mxg4a3Y97Mt","colab_type":"code","outputId":"46e9d249-d3cf-4038-fca0-d4d1e2d03dea","executionInfo":{"status":"ok","timestamp":1579986830231,"user_tz":-60,"elapsed":89837,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n","!unzip uncased_L-12_H-768_A-12.zip"],"execution_count":15,"outputs":[{"output_type":"stream","text":["--2020-01-25 21:13:40--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c08::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 407727028 (389M) [application/zip]\n","Saving to: ‘uncased_L-12_H-768_A-12.zip’\n","\n","uncased_L-12_H-768_ 100%[===================>] 388.84M   127MB/s    in 3.1s    \n","\n","2020-01-25 21:13:43 (127 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n","\n","Archive:  uncased_L-12_H-768_A-12.zip\n","   creating: uncased_L-12_H-768_A-12/\n","  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n","  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n","  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n","  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n","  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KlzqsoCERraJ","colab_type":"text"},"source":["### Building a tf.Module"]},{"cell_type":"code","metadata":{"id":"cOyKrgZRRqZe","colab_type":"code","colab":{}},"source":["def build_module_fn(config_path, vocab_path, do_lower_case=True):\n","\n","    def bert_module_fn(is_training):\n","        \"\"\"Spec function for a token embedding module.\"\"\"\n","\n","        input_ids = tf.placeholder(shape=[None, None], dtype=tf.int32, name=\"input_ids\")\n","        input_mask = tf.placeholder(shape=[None, None], dtype=tf.int32, name=\"input_mask\")\n","        token_type = tf.placeholder(shape=[None, None], dtype=tf.int32, name=\"segment_ids\")\n","\n","        config = BertConfig.from_json_file(config_path)\n","        model = BertModel(config=config, is_training=is_training,\n","                          input_ids=input_ids, input_mask=input_mask, token_type_ids=token_type)\n","          \n","        seq_output = model.all_encoder_layers[-1]\n","        pool_output = model.get_pooled_output()\n","\n","        config_file = tf.constant(value=config_path, dtype=tf.string, name=\"config_file\")\n","        vocab_file = tf.constant(value=vocab_path, dtype=tf.string, name=\"vocab_file\")\n","        lower_case = tf.constant(do_lower_case)\n","\n","        tf.add_to_collection(tf.GraphKeys.ASSET_FILEPATHS, config_file)\n","        tf.add_to_collection(tf.GraphKeys.ASSET_FILEPATHS, vocab_file)\n","            \n","        input_map = {\"input_ids\": input_ids,\n","                     \"input_mask\": input_mask,\n","                     \"segment_ids\": token_type}\n","        \n","        output_map = {\"pooled_output\": pool_output,\n","                      \"sequence_output\": seq_output}\n","\n","        output_info_map = {\"vocab_file\": vocab_file,\n","                           \"do_lower_case\": lower_case}\n","                \n","        hub.add_signature(name=\"tokens\", inputs=input_map, outputs=output_map)\n","        hub.add_signature(name=\"tokenization_info\", inputs={}, outputs=output_info_map)\n","\n","    return bert_module_fn"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ubGdlgtTsjW1","colab_type":"text"},"source":["### Exporting the module"]},{"cell_type":"code","metadata":{"id":"d4fShtfnSQbO","colab_type":"code","cellView":"both","outputId":"24e231ce-4434-4be7-9dbb-7072cc4f2312","executionInfo":{"status":"ok","timestamp":1579986850732,"user_tz":-60,"elapsed":110322,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["MODEL_DIR = \"uncased_L-12_H-768_A-12\" #@param {type:\"string\"} ['uncased_L-12_H-768_A-12']\n","\n","config_path = \"/content/{}/bert_config.json\".format(MODEL_DIR)\n","vocab_path = \"/content/{}/vocab.txt\".format(MODEL_DIR)\n","\n","tags_and_args = []\n","for is_training in (True, False):\n","  tags = set()\n","  if is_training:\n","    tags.add(\"train\")\n","  tags_and_args.append((tags, dict(is_training=is_training)))\n","\n","module_fn = build_module_fn(config_path, vocab_path)\n","spec = hub.create_module_spec(module_fn, tags_and_args=tags_and_args)\n","spec.export(\"bert-module\", \n","            checkpoint_path=\"/content/{}/bert_model.ckpt\".format(MODEL_DIR))\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["From bert_repo/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","From bert_repo/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","From bert_repo/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","From bert_repo/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","From bert_repo/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","From bert_repo/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","From /usr/local/lib/python3.6/dist-packages/tensorflow_hub/saved_model_lib.py:110: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"0xgf8hzNYMst","colab_type":"text"},"source":["### Building the text preprocessing pipeline"]},{"cell_type":"markdown","metadata":{"id":"cU5PvDyWBMiU","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"CMkUX6C5V3r7","colab_type":"code","colab":{}},"source":["def read_examples(str_list):\n","    \"\"\"Read a list of `InputExample`s from a list of strings.\"\"\"\n","    unique_id = 0\n","    for s in str_list:\n","        line = convert_to_unicode(s)\n","        if not line:\n","            continue\n","        \n","        text_a = line.strip()\n","        yield InputExample(unique_id=unique_id, text_a=text_a, text_b=None)\n","        unique_id += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmsepoRxVsc2","colab_type":"code","colab":{}},"source":["def features_to_arrays(features):\n","\n","    all_input_ids = []\n","    all_input_mask = []\n","    all_segment_ids = []\n","\n","    for feature in features:\n","        all_input_ids.append(feature.input_ids)\n","        all_input_mask.append(feature.input_mask)\n","        all_segment_ids.append(feature.input_type_ids)\n","\n","    return (np.array(all_input_ids, dtype='int32'), \n","            np.array(all_input_mask, dtype='int32'), \n","            np.array(all_segment_ids, dtype='int32'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_061naESlic","colab_type":"code","colab":{}},"source":["def build_preprocessor(voc_path, seq_len, lower=True):\n","    tokenizer = FullTokenizer(vocab_file=voc_path, do_lower_case=lower)\n","\n","    def strings_to_arrays(sents):\n","\n","        sents = np.atleast_1d(sents).reshape((-1,))\n","\n","        examples = []\n","        for example in read_examples(sents):\n","            example.text_a = preprocess_bert_before_tokenization(example.text_a)\n","            examples.append(example)\n","\n","        features = convert_examples_to_features(examples, seq_len, tokenizer)\n","        arrays = features_to_arrays(features)\n","        \n","        return arrays\n","\n","    return strings_to_arrays"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LycbxDVlalim","colab_type":"text"},"source":["### Implementing a BERT Keras layer"]},{"cell_type":"code","metadata":{"id":"MIIv5wCKUkgX","colab_type":"code","colab":{}},"source":["class BertLayer(tf.keras.layers.Layer):\n","    def __init__(self, bert_path, seq_len=64, n_tune_layers=3, \n","                 pooling=\"cls\", do_preprocessing=True, verbose=False,\n","                 tune_embeddings=False, trainable=True, **kwargs):\n","\n","        self.trainable = trainable\n","        self.n_tune_layers = n_tune_layers\n","        self.tune_embeddings = tune_embeddings\n","        self.do_preprocessing = do_preprocessing\n","\n","        self.verbose = verbose\n","        self.seq_len = seq_len\n","        self.pooling = pooling\n","        self.bert_path = bert_path\n","\n","        self.var_per_encoder = 16\n","        if self.pooling not in [\"cls\", \"mean\", None]:\n","            raise NameError(\n","                f\"Undefined pooling type (must be either 'cls', 'mean', or None, but is {self.pooling}\"\n","            )\n","\n","        super(BertLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","\n","        self.bert = hub.Module(self.build_abspath(self.bert_path), \n","                               trainable=self.trainable, name=f\"{self.name}_module\")\n","\n","        trainable_layers = []\n","        if self.tune_embeddings:\n","            trainable_layers.append(\"embeddings\")\n","\n","        if self.pooling == \"cls\":\n","            trainable_layers.append(\"pooler\")\n","\n","        if self.n_tune_layers > 0:\n","            encoder_var_names = [var.name for var in self.bert.variables if 'encoder' in var.name]\n","            n_encoder_layers = int(len(encoder_var_names) / self.var_per_encoder)\n","            for i in range(self.n_tune_layers):\n","                trainable_layers.append(f\"encoder/layer_{str(n_encoder_layers - 1 - i)}/\")\n","        \n","        # Add module variables to layer's trainable weights\n","        for var in self.bert.variables:\n","            if any([l in var.name for l in trainable_layers]):\n","                self._trainable_weights.append(var)\n","            else:\n","                self._non_trainable_weights.append(var)\n","\n","        if self.verbose:\n","            print(\"*** TRAINABLE VARS *** \")\n","            for var in self._trainable_weights:\n","                print(var)\n","\n","        self.build_preprocessor()\n","        self.initialize_module()\n","\n","        super(BertLayer, self).build(input_shape)\n","\n","    def build_abspath(self, path):\n","        if path.startswith(\"https://\") or path.startswith(\"gs://\"):\n","          return path\n","        else:\n","          return os.path.abspath(path)\n","\n","    def build_preprocessor(self):\n","        sess = tf.keras.backend.get_session()\n","        tokenization_info = self.bert(signature=\"tokenization_info\", as_dict=True)\n","        vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                              tokenization_info[\"do_lower_case\"]])\n","        self.preprocessor = build_preprocessor(vocab_file, self.seq_len, do_lower_case)\n","\n","    def initialize_module(self):\n","        sess = tf.keras.backend.get_session()\n","        \n","        vars_initialized = sess.run([tf.is_variable_initialized(var) \n","                                     for var in self.bert.variables])\n","\n","        uninitialized = []\n","        for var, is_initialized in zip(self.bert.variables, vars_initialized):\n","            if not is_initialized:\n","                uninitialized.append(var)\n","\n","        if len(uninitialized):\n","            sess.run(tf.variables_initializer(uninitialized))\n","\n","    def call(self, input):\n","\n","        if self.do_preprocessing:\n","          input = tf.numpy_function(self.preprocessor, \n","                                    [input], [tf.int32, tf.int32, tf.int32], \n","                                    name='preprocessor')\n","          for feature in input:\n","            feature.set_shape((None, self.seq_len))\n","        \n","        input_ids, input_mask, segment_ids = input\n","        \n","        bert_inputs = dict(\n","            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n","        )\n","        output = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n","        \n","        if self.pooling == \"cls\":\n","            pooled = output[\"pooled_output\"]\n","        else:\n","            result = output[\"sequence_output\"]\n","            \n","            input_mask = tf.cast(input_mask, tf.float32)\n","            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n","            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n","                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n","            \n","            if self.pooling == \"mean\":\n","              pooled = masked_reduce_mean(result, input_mask)\n","            else:\n","              pooled = mul_mask(result, input_mask)\n","\n","        return pooled\n","\n","    def get_config(self):\n","        config_dict = {\n","            \"bert_path\": self.bert_path, \n","            \"seq_len\": self.seq_len,\n","            \"pooling\": self.pooling,\n","            \"n_tune_layers\": self.n_tune_layers,\n","            \"tune_embeddings\": self.tune_embeddings,\n","            \"do_preprocessing\": self.do_preprocessing,\n","            \"verbose\": self.verbose\n","        }\n","        super(BertLayer, self).get_config()\n","        return config_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IIjYf1EL_nQA","colab_type":"text"},"source":["### Classification"]},{"cell_type":"code","metadata":{"id":"5BQLsvYzaysD","colab_type":"code","outputId":"7833906c-632f-4fa6-cea0-99a8891d8cd7","executionInfo":{"status":"ok","timestamp":1579986866719,"user_tz":-60,"elapsed":126278,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["inp = tf.keras.Input(shape=(1,), dtype=tf.string)\n","encoder = BertLayer(bert_path=\"./bert-module/\", seq_len=256, tune_embeddings=False,\n","                    pooling='cls', n_tune_layers=4, verbose=False)\n","\n","l1 = tf.keras.layers.Dense(768, activation='relu')\n","l2 = tf.keras.layers.Dense(768, activation='relu')\n","l3 = tf.keras.layers.Dense(768, activation='relu')\n","d = tf.keras.layers.Dropout(0.5)\n","\n","pred = tf.keras.layers.Dense(3, activation='softmax')(d(l3(l2(l1(encoder(inp))))))\n","\n","model = tf.keras.models.Model(inputs=[inp], outputs=[pred])"],"execution_count":22,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2DmN-x8-FgAm","colab_type":"code","colab":{}},"source":["import keras.backend as K\n","\n","def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH-6kHUmZ7Uh","colab_type":"code","colab":{}},"source":["from sklearn.utils import class_weight\n","\n","class_weights = class_weight.compute_class_weight('balanced',\n","                                            np.unique(training_y),\n","                                            training_y)\n","class_weights /= max(class_weights)\n","\n","def weighted_loss(actual, predicted):\n","  bce = tf.keras.losses.SparseCategoricalCrossentropy()\n","  loss = bce(actual, predicted)\n","  \n","  return tf.keras.backend.mean(loss * class_weights)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxuy1OMCbGTw","colab_type":"code","outputId":"46d44c6e-0610-42d0-ba64-f8d00a63ef0f","executionInfo":{"status":"ok","timestamp":1579986866727,"user_tz":-60,"elapsed":126267,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["model.summary()\n","\n","model.compile(\n","      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, ),\n","      loss=weighted_loss,\n","      metrics=['accuracy'])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 1)]               0         \n","_________________________________________________________________\n","bert_layer (BertLayer)       (None, 768)               109482240 \n","_________________________________________________________________\n","dense (Dense)                (None, 768)               590592    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 768)               590592    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 768)               590592    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 768)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 3)                 2307      \n","=================================================================\n","Total params: 111,256,323\n","Trainable params: 30,716,163\n","Non-trainable params: 80,540,160\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0V7AbjTBifTl","colab_type":"text"},"source":["### Training"]},{"cell_type":"code","metadata":{"id":"2lbagCxaieoG","colab_type":"code","colab":{}},"source":["import logging\n","logging.getLogger(\"tensorflow\").setLevel(logging.WARNING)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6svZ93niek0","colab_type":"code","outputId":"cfa78c3d-4559-49a9-85f2-61a4e53b7331","executionInfo":{"status":"ok","timestamp":1579987936056,"user_tz":-60,"elapsed":214907,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["saver = keras.callbacks.ModelCheckpoint(\"bert_H6_S256_B32.hdf5\")\n","\n","history = model.fit(training_x, training_y, validation_data=[validation_x, validation_y], batch_size=64, epochs=1, callbacks=[saver])"],"execution_count":29,"outputs":[{"output_type":"stream","text":["3600/3600 [==============================] - 109s 30ms/sample - loss: 0.1531 - acc: 0.5161 - val_loss: 0.7177 - val_acc: 0.4675\n","Train on 3600 samples, validate on 400 samples\n","3600/3600 [==============================] - 109s 30ms/sample - loss: 0.1086 - acc: 0.5119 - val_loss: 0.7925 - val_acc: 0.4550\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TwOSC395hUmY","colab_type":"text"},"source":["### Loss function graph"]},{"cell_type":"code","metadata":{"id":"v_-ROTbohUXE","colab_type":"code","outputId":"9cbb2e90-23a3-4d72-9f22-14cdbf4158ea","executionInfo":{"status":"ok","timestamp":1579987938207,"user_tz":-60,"elapsed":217037,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":30,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"yvpDQTLuaXyb","colab_type":"text"},"source":["## Test prediction"]},{"cell_type":"code","metadata":{"id":"kHX7kuajacQ0","colab_type":"code","outputId":"6e3ba264-a0d9-490a-8705-304cd3339089","executionInfo":{"status":"ok","timestamp":1579988024268,"user_tz":-60,"elapsed":303084,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# pred = model.predict(test_dataset['Tweet'][:20])\n","pred = model.predict(test_dataset['Tweet'])\n","pred"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.02171669, 0.16911396, 0.80916935],\n","       [0.01284359, 0.16907896, 0.81807745],\n","       [0.975009  , 0.02274468, 0.00224623],\n","       ...,\n","       [0.01867083, 0.8694292 , 0.1119    ],\n","       [0.975009  , 0.02274468, 0.00224623],\n","       [0.02694062, 0.96316934, 0.00988997]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"xvANxMHxboHl","colab_type":"code","colab":{}},"source":["y_pred = np.argmax(pred, axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EujRcP0Kb3us","colab_type":"code","outputId":"d616d23c-910d-4ccf-93d6-e2281b3505e6","executionInfo":{"status":"ok","timestamp":1579988024271,"user_tz":-60,"elapsed":303065,"user":{"displayName":"Mateusz Skiba","photoUrl":"","userId":"04465528267736206115"}},"colab":{"base_uri":"https://localhost:8080/","height":669}},"source":["results = pd.DataFrame()\n","# results['Id'] = test_dataset['Id'][:20].map(int)\n","# results['Id'] = test_dataset['Id'].map(int)\n","results['Id'] = test_dataset['Id']\n","results['Category'] = np.argmax(pred, axis=1)\n","results = results.replace({ 'Category': { 0: 'positive', 1: 'neutral', 2: 'negative'}})\n","results[:20]"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>628949369883000832</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>628976607420645377</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>629023169169518592</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>629179223232479232</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>629186282179153920</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>629226490152914944</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>629345637155360768</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>629394528336637953</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>629650766580609026</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>629797991826722816</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>630159517058142208</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>630542330827771904</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>630636736746422272</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>630807124872970240</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>630818265799921664</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>630909171437801472</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>630982270409572352</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>631104156187627520</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>631223085476261890</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>631368262979297281</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    Id  Category\n","0   628949369883000832  negative\n","1   628976607420645377  negative\n","2   629023169169518592  positive\n","3   629179223232479232  positive\n","4   629186282179153920   neutral\n","5   629226490152914944  positive\n","6   629345637155360768  negative\n","7   629394528336637953  negative\n","8   629650766580609026  positive\n","9   629797991826722816  negative\n","10  630159517058142208  positive\n","11  630542330827771904  negative\n","12  630636736746422272  negative\n","13  630807124872970240   neutral\n","14  630818265799921664  positive\n","15  630909171437801472   neutral\n","16  630982270409572352   neutral\n","17  631104156187627520  negative\n","18  631223085476261890  negative\n","19  631368262979297281  positive"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"Vr2QGqfEdZlN","colab_type":"code","colab":{}},"source":["results.to_csv('gdrive/My Drive/ITI/EMD/results.csv', index=False)"],"execution_count":0,"outputs":[]}]}